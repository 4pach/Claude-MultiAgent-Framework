#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Cache Manager - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫—ç—à–µ–º MCP –∑–∞–ø—Ä–æ—Å–æ–≤
–ß–∞—Å—Ç—å Claude MultiAgent Framework

–ê–≤—Ç–æ—Ä: Claude MultiAgent System
–î–∞—Ç–∞: 2025-07-11
"""

import json
import hashlib
import pickle
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import gzip
import sqlite3

@dataclass
class CacheEntry:
    """–ó–∞–ø–∏—Å—å –≤ –∫—ç—à–µ"""
    key: str
    agent: str
    mcp_server: str
    query_hash: str
    response_data: Any
    tokens_used: int
    response_time: float
    created_at: datetime
    expires_at: datetime
    access_count: int
    last_accessed: datetime
    quality_score: float

@dataclass
class CacheStats:
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞"""
    total_entries: int
    total_size_mb: float
    hit_rate: float
    miss_rate: float
    space_efficiency: float
    avg_access_count: float
    expiration_rate: float

class IntelligentCacheManager:
    """–ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∞ MCP –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self, cache_dir: str = "monitoring/cache", max_size_mb: float = 100.0):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        self.max_size_mb = max_size_mb
        self.lock = threading.RLock()
        
        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫—ç—à–∞
        self.db_path = self.cache_dir / "cache_metadata.db"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.hits = 0
        self.misses = 0
        self.evictions = 0
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è TTL –ø–æ —Å–µ—Ä–≤–µ—Ä–∞–º
        self.server_ttl_config = {
            'context7': timedelta(hours=4),
            'github': timedelta(hours=24),
            'exa': timedelta(hours=12),
            'taskmaster-ai': timedelta(hours=2),
            'wcgw': timedelta(hours=1),
            'youtube-transcript': timedelta(hours=48),
            'playwright': timedelta(minutes=30),  # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã –∫—ç—à–∏—Ä—É—é—Ç—Å—è –Ω–µ–Ω–∞–¥–æ–ª–≥–æ
            'sequentialthinking': timedelta(minutes=0)  # –ù–µ –∫—ç—à–∏—Ä—É–µ—Ç—Å—è
        }
        
        # –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        self.quality_thresholds = {
            'min_tokens': 50,      # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            'max_tokens': 1500,    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ (—Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ –æ—Ç–≤–µ—Ç—ã –Ω–µ –∫—ç—à–∏—Ä—É–µ–º)
            'max_response_time': 20.0,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
            'min_quality_score': 0.6    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∫–∞—á–µ—Å—Ç–≤–∞
        }
        
        self.init_database()
    
    def init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫—ç—à–∞"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS cache_metadata (
                    key TEXT PRIMARY KEY,
                    agent TEXT NOT NULL,
                    mcp_server TEXT NOT NULL,
                    query_hash TEXT NOT NULL,
                    tokens_used INTEGER NOT NULL,
                    response_time REAL NOT NULL,
                    created_at TEXT NOT NULL,
                    expires_at TEXT NOT NULL,
                    access_count INTEGER DEFAULT 1,
                    last_accessed TEXT NOT NULL,
                    quality_score REAL NOT NULL,
                    file_size INTEGER NOT NULL
                )
            ''')
            
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_expires_at ON cache_metadata(expires_at)
            ''')
            
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_mcp_server ON cache_metadata(mcp_server)
            ''')
            
            conn.execute('''
                CREATE INDEX IF NOT EXISTS idx_last_accessed ON cache_metadata(last_accessed)
            ''')
    
    def generate_cache_key(self, agent: str, mcp_server: str, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–ø–∞–¥–∞–Ω–∏—è –≤ –∫—ç—à
        normalized_query = self.normalize_query(query)
        
        # –•—ç—à –æ—Ç –∞–≥–µ–Ω—Ç–∞, —Å–µ—Ä–≤–µ—Ä–∞ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        content = f"{agent}:{mcp_server}:{normalized_query}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]
    
    def normalize_query(self, query: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –∫—ç—à"""
        # –£–¥–∞–ª–µ–Ω–∏–µ –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
        normalized = " ".join(query.lower().strip().split())
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫ –∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        import re
        normalized = re.sub(r'\b\d{4}-\d{2}-\d{2}\b', 'DATE', normalized)
        normalized = re.sub(r'\b\d+\.\d+\.\d+\b', 'VERSION', normalized)
        normalized = re.sub(r'\bid\s*[:=]\s*\w+', 'id:ID', normalized)
        
        return normalized
    
    def calculate_quality_score(self, agent: str, mcp_server: str, query: str,
                               response_data: Any, tokens_used: int, 
                               response_time: float) -> float:
        """–†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ü–µ–Ω–Ω–æ—Å—Ç–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        score = 1.0
        
        # –§–∞–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–∞ –æ—Ç–≤–µ—Ç–∞ (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä = –≤—ã—Å–æ–∫–∏–π score)
        if tokens_used < self.quality_thresholds['min_tokens']:
            score *= 0.3  # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–π –æ—Ç–≤–µ—Ç
        elif tokens_used > self.quality_thresholds['max_tokens']:
            score *= 0.2  # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π –æ—Ç–≤–µ—Ç
        else:
            # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä (200-800 —Ç–æ–∫–µ–Ω–æ–≤)
            optimal_range = (200, 800)
            if optimal_range[0] <= tokens_used <= optimal_range[1]:
                score *= 1.0
            else:
                distance = min(abs(tokens_used - optimal_range[0]), 
                              abs(tokens_used - optimal_range[1]))
                score *= max(0.5, 1.0 - distance / 1000)
        
        # –§–∞–∫—Ç–æ—Ä –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ (–±—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –º–µ–Ω–µ–µ —Ü–µ–Ω–Ω—ã –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è)
        if response_time > 5.0:
            score *= 1.2  # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±–æ–ª–µ–µ —Ü–µ–Ω–Ω—ã –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        elif response_time < 1.0:
            score *= 0.7  # –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–ø—Ä–æ—Å—ã –º–µ–Ω–µ–µ —Ü–µ–Ω–Ω—ã
        
        # –§–∞–∫—Ç–æ—Ä —Ç–∏–ø–∞ —Å–µ—Ä–≤–µ—Ä–∞
        server_priority = {
            'context7': 1.3,      # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —á–∞—Å—Ç–æ –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
            'github': 1.2,        # –ü–æ–∏—Å–∫ –∫–æ–¥–∞ —Å—Ç–∞–±–∏–ª–µ–Ω
            'exa': 1.1,          # –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ–ª–µ–∑–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å
            'taskmaster-ai': 0.8, # –ü–ª–∞–Ω—ã —á–∞—Å—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã
            'wcgw': 0.6,         # –°–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã –º–µ–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã
            'youtube-transcript': 1.5, # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ –Ω–µ –º–µ–Ω—è—é—Ç—Å—è
            'playwright': 0.3,    # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç–µ—Å—Ç—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã
            'sequentialthinking': 0.0  # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –Ω–µ –∫—ç—à–∏—Ä—É—é—Ç—Å—è
        }
        score *= server_priority.get(mcp_server, 1.0)
        
        # –§–∞–∫—Ç–æ—Ä –∞–≥–µ–Ω—Ç–∞ (–Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∞–≥–µ–Ω—Ç—ã –±–æ–ª–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º—ã)
        agent_priority = {
            'architect': 1.2,     # –ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ —á–∞—Å—Ç–æ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç—Å—è
            'engineer': 1.1,      # –ü–æ–∏—Å–∫ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–¥–∞
            'integrator': 1.0,    # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —É–º–µ—Ä–µ–Ω–Ω–æ –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è
            'critic': 0.9,        # –ê–Ω–∞–ª–∏–∑ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –±–æ–ª–µ–µ —É–Ω–∏–∫–∞–ª–µ–Ω
            'manager': 0.8,       # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —á–∞—Å—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ
            'optimizer': 1.3      # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ —Å—Ç–∞–±–∏–ª–µ–Ω
        }
        score *= agent_priority.get(agent, 1.0)
        
        return min(1.0, max(0.0, score))
    
    def should_cache(self, agent: str, mcp_server: str, query: str,
                    response_data: Any, tokens_used: int, 
                    response_time: float) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑–æ–≤—ã—Ö –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
        if tokens_used < self.quality_thresholds['min_tokens']:
            return False
        
        if tokens_used > self.quality_thresholds['max_tokens']:
            return False
        
        if response_time > self.quality_thresholds['max_response_time']:
            return False
        
        # –°–µ—Ä–≤–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∫—ç—à–∏—Ä—É—é—Ç—Å—è
        if mcp_server in ['sequentialthinking', 'playwright']:
            return False
        
        # –†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª—è –∫–∞—á–µ—Å—Ç–≤–∞
        quality_score = self.calculate_quality_score(
            agent, mcp_server, query, response_data, tokens_used, response_time
        )
        
        return quality_score >= self.quality_thresholds['min_quality_score']
    
    def get_ttl(self, mcp_server: str) -> timedelta:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∂–∏–∑–Ω–∏ –¥–ª—è —Å–µ—Ä–≤–µ—Ä–∞"""
        return self.server_ttl_config.get(mcp_server, timedelta(hours=1))
    
    def store(self, agent: str, mcp_server: str, query: str, response_data: Any,
             tokens_used: int, response_time: float) -> Optional[str]:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –≤ –∫—ç—à"""
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        if not self.should_cache(agent, mcp_server, query, response_data, 
                                tokens_used, response_time):
            return None
        
        with self.lock:
            cache_key = self.generate_cache_key(agent, mcp_server, query)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–∞—è –∑–∞–ø–∏—Å—å
            if self.exists(cache_key):
                self.update_access(cache_key)
                return cache_key
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∫—ç—à–∞
            now = datetime.now()
            ttl = self.get_ttl(mcp_server)
            expires_at = now + ttl
            
            quality_score = self.calculate_quality_score(
                agent, mcp_server, query, response_data, tokens_used, response_time
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–∞–π–ª
            file_path = self.cache_dir / f"{cache_key}.gz"
            with gzip.open(file_path, 'wb') as f:
                pickle.dump(response_data, f)
            
            file_size = file_path.stat().st_size
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –≤ –ë–î
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    INSERT OR REPLACE INTO cache_metadata
                    (key, agent, mcp_server, query_hash, tokens_used, response_time,
                     created_at, expires_at, access_count, last_accessed, 
                     quality_score, file_size)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    cache_key, agent, mcp_server, str(hash(query)), tokens_used,
                    response_time, now.isoformat(), expires_at.isoformat(),
                    1, now.isoformat(), quality_score, file_size
                ))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–æ–≤ —Ä–∞–∑–º–µ—Ä–∞
            self.enforce_size_limits()
            
            return cache_key
    
    def retrieve(self, agent: str, mcp_server: str, query: str) -> Optional[Tuple[Any, Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –∏–∑ –∫—ç—à–∞"""
        with self.lock:
            cache_key = self.generate_cache_key(agent, mcp_server, query)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏
            if not self.exists(cache_key) or self.is_expired(cache_key):
                self.misses += 1
                return None
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            file_path = self.cache_dir / f"{cache_key}.gz"
            try:
                with gzip.open(file_path, 'rb') as f:
                    response_data = pickle.load(f)
                
                # –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                metadata = self.get_metadata(cache_key)
                if not metadata:
                    self.misses += 1
                    return None
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ—Å—Ç—É–ø–∞
                self.update_access(cache_key)
                self.hits += 1
                
                return response_data, metadata
                
            except Exception as e:
                # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
                self.remove(cache_key)
                self.misses += 1
                return None
    
    def exists(self, cache_key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è –∑–∞–ø–∏—Å–∏ –≤ –∫—ç—à–µ"""
        file_path = self.cache_dir / f"{cache_key}.gz"
        return file_path.exists()
    
    def is_expired(self, cache_key: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–µ—á–µ–Ω–∏—è —Å—Ä–æ–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT expires_at FROM cache_metadata WHERE key = ?
            ''', (cache_key,))
            
            row = cursor.fetchone()
            if not row:
                return True
            
            expires_at = datetime.fromisoformat(row[0])
            return datetime.now() > expires_at
    
    def get_metadata(self, cache_key: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–∏"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT * FROM cache_metadata WHERE key = ?
            ''', (cache_key,))
            
            row = cursor.fetchone()
            if not row:
                return None
            
            columns = [desc[0] for desc in cursor.description]
            return dict(zip(columns, row))
    
    def update_access(self, cache_key: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–æ—Å—Ç—É–ø–∞"""
        now = datetime.now()
        with sqlite3.connect(self.db_path) as conn:
            conn.execute('''
                UPDATE cache_metadata 
                SET access_count = access_count + 1, last_accessed = ?
                WHERE key = ?
            ''', (now.isoformat(), cache_key))
    
    def remove(self, cache_key: str) -> bool:
        """–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–∞"""
        with self.lock:
            file_path = self.cache_dir / f"{cache_key}.gz"
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
            if file_path.exists():
                file_path.unlink()
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    DELETE FROM cache_metadata WHERE key = ?
                ''', (cache_key,))
                
                return cursor.rowcount > 0
    
    def cleanup_expired(self) -> int:
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        with self.lock:
            now = datetime.now()
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT key FROM cache_metadata WHERE expires_at < ?
                ''', (now.isoformat(),))
                
                expired_keys = [row[0] for row in cursor.fetchall()]
            
            # –£–¥–∞–ª–µ–Ω–∏–µ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π
            removed_count = 0
            for key in expired_keys:
                if self.remove(key):
                    removed_count += 1
            
            return removed_count
    
    def enforce_size_limits(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤ —Ä–∞–∑–º–µ—Ä–∞"""
        current_size = self.get_cache_size_mb()
        
        if current_size <= self.max_size_mb:
            return
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –Ω–∞–∏–º–µ–Ω–µ–µ —Ü–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT key, quality_score, access_count, last_accessed
                FROM cache_metadata
                ORDER BY quality_score ASC, access_count ASC, last_accessed ASC
            ''')
            
            entries_to_remove = []
            for row in cursor.fetchall():
                entries_to_remove.append(row[0])
                if len(entries_to_remove) >= 10:  # –£–¥–∞–ª—è–µ–º –±–∞—Ç—á–∞–º–∏
                    break
        
        # –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π
        removed_count = 0
        for key in entries_to_remove:
            if self.remove(key):
                removed_count += 1
                self.evictions += 1
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
            if self.get_cache_size_mb() <= self.max_size_mb * 0.9:
                break
    
    def get_cache_size_mb(self) -> float:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –∫—ç—à–∞ –≤ –ú–ë"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT SUM(file_size) FROM cache_metadata
            ''')
            
            total_bytes = cursor.fetchone()[0] or 0
            return total_bytes / (1024 * 1024)
    
    def get_cache_statistics(self) -> CacheStats:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT COUNT(*), AVG(access_count), SUM(file_size)
                FROM cache_metadata
            ''')
            
            total_entries, avg_access_count, total_size_bytes = cursor.fetchone()
            total_entries = total_entries or 0
            avg_access_count = avg_access_count or 0
            total_size_bytes = total_size_bytes or 0
            
            # –†–∞—Å—á–µ—Ç –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π
            total_requests = self.hits + self.misses
            hit_rate = self.hits / total_requests if total_requests > 0 else 0
            miss_rate = self.misses / total_requests if total_requests > 0 else 0
            
            # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞
            max_size_bytes = self.max_size_mb * 1024 * 1024
            space_efficiency = total_size_bytes / max_size_bytes if max_size_bytes > 0 else 0
            
            # –°–∫–æ—Ä–æ—Å—Ç—å –∏—Å—Ç–µ—á–µ–Ω–∏—è
            cursor = conn.execute('''
                SELECT COUNT(*) FROM cache_metadata WHERE expires_at < ?
            ''', (datetime.now().isoformat(),))
            expired_count = cursor.fetchone()[0] or 0
            expiration_rate = expired_count / total_entries if total_entries > 0 else 0
        
        return CacheStats(
            total_entries=total_entries,
            total_size_mb=total_size_bytes / (1024 * 1024),
            hit_rate=hit_rate,
            miss_rate=miss_rate,
            space_efficiency=space_efficiency,
            avg_access_count=avg_access_count,
            expiration_rate=expiration_rate
        )
    
    def print_cache_report(self):
        """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é –∫—ç—à–∞"""
        stats = self.get_cache_statistics()
        
        print("\n" + "="*50)
        print("[üíæ Cache Manager] === –û–¢–ß–ï–¢ –ü–û –ö–≠–®–£ ===")
        print("="*50)
        print(f"üìä –í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {stats.total_entries}")
        print(f"üíæ –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {stats.total_size_mb:.1f} –ú–ë / {self.max_size_mb} –ú–ë")
        print(f"üéØ Hit rate: {stats.hit_rate:.1%}")
        print(f"‚ùå Miss rate: {stats.miss_rate:.1%}")
        print(f"üìà –°—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {stats.avg_access_count:.1f} —Ä–∞–∑")
        print(f"‚è∞ –ò—Å—Ç–µ–∫—à–∏—Ö –∑–∞–ø–∏—Å–µ–π: {stats.expiration_rate:.1%}")
        print(f"üóëÔ∏è –í—ã—Ç–µ—Å–Ω–µ–Ω–∏–π: {self.evictions}")
        
        # –¢–æ–ø —Å–µ—Ä–≤–µ—Ä–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∑–∞–ø–∏—Å–µ–π
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute('''
                SELECT mcp_server, COUNT(*), AVG(access_count)
                FROM cache_metadata
                GROUP BY mcp_server
                ORDER BY COUNT(*) DESC
                LIMIT 5
            ''')
            
            print("\nüèÜ –¢–æ–ø —Å–µ—Ä–≤–µ—Ä–æ–≤ –≤ –∫—ç—à–µ:")
            for row in cursor.fetchall():
                server, count, avg_access = row
                print(f"  ‚Ä¢ {server}: {count} –∑–∞–ø–∏—Å–µ–π (—Å—Ä–µ–¥–Ω–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {avg_access:.1f})")
        
        print("="*50)
    
    def optimize_cache(self) -> Dict[str, int]:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—ç—à–∞ (–æ—á–∏—Å—Ç–∫–∞ –∏ —Ä–µ–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è)"""
        with self.lock:
            operations = {
                'expired_removed': self.cleanup_expired(),
                'low_quality_removed': 0,
                'defragmented': 0
            }
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–µ–π —Å –Ω–∏–∑–∫–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –∏ —Ä–µ–¥–∫–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT key FROM cache_metadata 
                    WHERE quality_score < 0.4 AND access_count <= 1
                    AND created_at < ?
                ''', ((datetime.now() - timedelta(hours=24)).isoformat(),))
                
                low_quality_keys = [row[0] for row in cursor.fetchall()]
            
            for key in low_quality_keys:
                if self.remove(key):
                    operations['low_quality_removed'] += 1
            
            # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —Å–æ–±–ª—é–¥–µ–Ω–∏–µ –ª–∏–º–∏—Ç–æ–≤
            self.enforce_size_limits()
            
            return operations

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –∫—ç—à–∞
cache_manager = IntelligentCacheManager()

def cache_mcp_response(agent: str, mcp_server: str, query: str, response_data: Any,
                      tokens_used: int, response_time: float) -> Optional[str]:
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ MCP"""
    return cache_manager.store(agent, mcp_server, query, response_data, 
                              tokens_used, response_time)

def get_cached_mcp_response(agent: str, mcp_server: str, query: str) -> Optional[Tuple[Any, Dict]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ MCP"""
    return cache_manager.retrieve(agent, mcp_server, query)

def cleanup_cache() -> int:
    """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–µ–≥–æ –∫—ç—à–∞"""
    return cache_manager.cleanup_expired()

def optimize_cache() -> Dict[str, int]:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∫—ç—à–∞"""
    return cache_manager.optimize_cache()

def print_cache_report():
    """–í—ã–≤–æ–¥ –æ—Ç—á–µ—Ç–∞ –ø–æ –∫—ç—à—É"""
    cache_manager.print_cache_report()

if __name__ == "__main__":
    # –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–±–æ—Ç—ã –∫—ç—à–∞
    print("üíæ Intelligent Cache Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    # –ü—Ä–∏–º–µ—Ä—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    cache = IntelligentCacheManager()
    
    # –¢–µ—Å—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    test_response = {"result": "test data", "tokens": 300}
    cache_key = cache.store("architect", "context7", "test query", 
                           test_response, 300, 2.5)
    
    if cache_key:
        print(f"‚úÖ –û—Ç–≤–µ—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω: {cache_key}")
        
        # –¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞
        cached_data = cache.retrieve("architect", "context7", "test query")
        if cached_data:
            print("‚úÖ –û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –∏–∑ –∫—ç—à–∞")
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑ –∫—ç—à–∞")
    
    cache.print_cache_report()